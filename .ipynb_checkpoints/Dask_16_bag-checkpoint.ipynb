{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask Bag - CMIP6 Indexer Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We demonstrate how to use Dask.bag to read and process semi-structured data such as JSON.\n",
    "\n",
    "* load JSON files\n",
    "* Parse json object as dictionary\n",
    "* Apply map, filter, group\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Authors: NCI Virtual Research Environment Team\n",
    "- Keywords: Dask bag, JSON \n",
    "- Create Date: 2020-Sep\n",
    "- Lineage/Reference: This tutorial is referenced to [dask tutorial](https://github.com/dask/dask-tutorial).\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Dask.bag\n",
    "\n",
    "Dask-bag excels in processing data that can be represented as a sequence of arbitrary inputs. We'll refer to this as \"messy\" data, because it can contain complex nested structures, missing fields, mixtures of data types, etc. The *functional* programming style fits very nicely with standard Python iteration, such as can be found in the `itertools` module.\n",
    "\n",
    "Messy data is often encountered at the beginning of data processing pipelines when large volumes of raw data are first consumed. The initial set of data might be JSON, CSV, XML, or any other format that does not enforce strict structure and datatypes.\n",
    "For this reason, the initial data massaging and processing is often done with Python `list`s, `dict`s, and `set`s.\n",
    "\n",
    "These core data structures are optimized for general-purpose storage and processing.  Adding streaming computation with iterators/generator expressions or libraries like `itertools` or [`toolz`](https://toolz.readthedocs.io/en/latest/) let us process large volumes in a small space.  If we combine this with parallel processing then we can churn through a fair amount of data.\n",
    "\n",
    "Dask.bag is a high level Dask collection to automate common workloads of this form.  In a nutshell\n",
    "\n",
    "    dask.bag = map, filter, toolz + parallel execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose from the following two options to create a client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://127.0.0.1:43867' processes=8 threads=48, memory=161.06 GB>\n"
     ]
    }
   ],
   "source": [
    "# If you run this notebook on your local computer or NCI's VDI instance, you can create cluster\n",
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you run this notebook on Gadi under pangeo environment, you can create cluster using scheduler.json file\n",
    "from dask.distributed import Client, LocalCluster\n",
    "client = Client(scheduler_file='../scheduler.json')\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Warning: Please make sure you specify the correct path to the schedular.json file within your environment.</b>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting the Dask Client will provide a dashboard which is useful to gain insight into the computation. The link to the dashboard will become visible when you create the Client. We recommend having the Client open on one side of your screen and your notebook open on the other side, which will be useful for learning purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a `Bag` from a Python sequence, from files, or from data on a remote service url, etc. We demonstrate using `.take()` to show elements of the data. (Doing `.take(1)` results in a tuple with one element)\n",
    "\n",
    "Note that the data are partitioned into blocks, and there are many items per block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first example, the two partitions contain five elements each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each element is an integer\n",
    "import dask.bag as db\n",
    "b1 = db.from_sequence([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], npartitions=2)\n",
    "b1.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second example, dask bag sequences a list with different data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_containers = [[0, 1, 2, 3],{},[6.5, 3.14], 'Python', {'version':3}, '' ]\n",
    "b2 = db.from_sequence(nested_containers) \n",
    "b2.count().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the third example, each file is partitioned into one or more bytes blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('{\"Conventions\": [\"CF-1.7 CMIP-6.2\"], \"activity_id\": [\"CMIP\"], \"branch_method\": [\"standard\"], \"creation_date\": [\"2019-11-15T02:37:21Z\"], \"data_specs_version\": [\"01.00.30\"], \"experiment\": [\"1 percent per year increase in CO2\"], \"experiment_id\": [\"1pctCO2\"], \"external_variables\": [\"areacella\"], \"frequency\": [\"mon\"], \"further_info_url\": [\"https://furtherinfo.es-doc.org/CMIP6.CSIRO.ACCESS-ESM1-5.1pctCO2.none.r1i1p1f1\"], \"grid\": [\"native atmosphere N96 grid (145x192 latxlon)\"], \"grid_label\": [\"gn\"], \"history\": [\"2019-11-15T02:37:21Z ; CMOR rewrote data to be consistent with CMIP6, CF-1.7 CMIP-6.2 and CF standards.\"], \"institution\": [\"Commonwealth Scientific and Industrial Research Organisation, Aspendale, Victoria 3195, Australia\"], \"institution_id\": [\"CSIRO\"], \"mip_era\": [\"CMIP6\"], \"nominal_resolution\": [\"250 km\"], \"notes\": [\"Exp: ESM-1pctCO2; Local ID: PI-1pct-01; Variable: tasmax ([\\'fld_s03i236_max\\'])\"], \"parent_activity_id\": [\"CMIP\"], \"parent_experiment_id\": [\"piControl\"], \"parent_mip_era\": [\"CMIP6\"], \"parent_source_id\": [\"ACCESS-ESM1-5\"], \"parent_time_units\": [\"days since 0101-01-01\"], \"parent_variant_label\": [\"r1i1p1f1\"], \"product\": [\"model-output\"], \"realm\": [\"atmos\"], \"run_variant\": [\"forcing: GHG, Oz, SA, Sl, Vl, BC, OC, (GHG = CO2, N2O, CH4, CFC11, CFC12, CFC113, HCFC22, HFC125, HFC134a)\"], \"source\": [\"ACCESS-ESM1.5 (2019): \\\\naerosol: CLASSIC (v1.0)\\\\natmos: HadGAM2 (r1.1, N96; 192 x 145 longitude/latitude; 38 levels; top level 39255 m)\\\\natmosChem: none\\\\nland: CABLE2.4\\\\nlandIce: none\\\\nocean: ACCESS-OM2 (MOM5, tripolar primarily 1deg; 360 x 300 longitude/latitude; 50 levels; top grid cell 0-10 m)\\\\nocnBgchem: WOMBAT (same grid as ocean)\\\\nseaIce: CICE4.1 (same grid as ocean)\"], \"source_id\": [\"ACCESS-ESM1-5\"], \"source_type\": [\"AOGCM\"], \"sub_experiment\": [\"none\"], \"sub_experiment_id\": [\"none\"], \"table_id\": [\"Amon\"], \"table_info\": [\"Creation Date:(30 April 2019) MD5:e14f55f257cceafb2523e41244962371\"], \"title\": [\"ACCESS-ESM1-5 output prepared for CMIP6\"], \"variable_id\": [\"tasmax\"], \"variant_label\": [\"r1i1p1f1\"], \"version\": [\"v20191115\"], \"cmor_version\": [\"3.4.0\"], \"tracking_id\": [\"hdl:21.14100/6c76911b-9543-47ee-9b8d-9e3e55a6de42\"], \"license\": [\"CMIP6 model data produced by CSIRO is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License (https://creativecommons.org/licenses/).  Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment.  Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file).  The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.\"]}',)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each element is a text file, where each line is a JSON object\n",
    "import os\n",
    "b3 = db.read_text(os.path.join('/g/data/dk92/notebooks/demo_data/cmip6_json','*.json'))\n",
    "b3.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Bag` objects hold the standard functional API found in projects like the Python standard library, `toolz`, or `pyspark`, including `map`, `filter`, `groupby`, etc..\n",
    "\n",
    "Operations on `Bag` objects create new bags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.bag<lambda, npartitions=10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each even number, calculate the power of 2 of this number\n",
    "def is_even(n):\n",
    "    return n % 2 == 0\n",
    "\n",
    "b = db.from_sequence([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "c = b.filter(is_even).map(lambda x: x ** 2)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either convert the dast.bag into a list by calling the `.compute()` method to trigger execution, as we saw for `Delayed` objects.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 16, 36, 64, 100]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 16, 36, 64, 100]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=c.compute()\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMIP6 Indexer data example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example data are global attributes from some CMIP6 data. Each file is a JSON encoded dictionary with a list of keys, which are basically CMIP6 vocabularies like:\n",
    "\n",
    "*  Conventions: CF-1.7 CMIP-6.2\n",
    "*  activity_id: CMIP\n",
    "*  creation_date: 2019-11-15T02:37:21Z\n",
    "*  experiment: 1 percent per year increase in CO2\n",
    "*  ...\n",
    "\n",
    "JavaScript Object Notation - JSON data files has the following great features:\n",
    "\n",
    "- stored as plain text\n",
    "- common web format\n",
    "- direct mapping to Python lists & Dictionaries\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing \n",
    "\n",
    "Dask.bag only take double quotas in the json object. Therefore, we need to replace the single quota with double quota in the json files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Python's glob module to search up all the historical model files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "files = glob.glob('/g/data/dk92/notebooks/demo_data/cmip6_json/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use json module to read the json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(files[0]) as f:\n",
    "    items = json.load(f)\n",
    "type(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CMIP6'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items['mip_era']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON files into Dask Bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('{\"Conventions\": \"CF-1.7 CMIP-6.2\", \"activity_id\": \"CMIP\", \"branch_method\": \"standard\", \"creation_date\": \"2019-11-15T02:38:12Z\", \"data_specs_version\": \"01.00.30\", \"experiment\": \"1 percent per year increase in CO2\", \"experiment_id\": \"1pctCO2\", \"external_variables\": \"areacella\", \"frequency\": \"mon\", \"further_info_url\": \"https://furtherinfo.es-doc.org/CMIP6.CSIRO.ACCESS-ESM1-5.1pctCO2.none.r1i1p1f1\", \"grid\": \"native atmosphere N96 grid (145x192 latxlon)\", \"grid_label\": \"gn\", \"history\": \"2019-11-15T02:38:12Z ; CMOR rewrote data to be consistent with CMIP6, CF-1.7 CMIP-6.2 and CF standards.\", \"institution\": \"Commonwealth Scientific and Industrial Research Organisation, Aspendale, Victoria 3195, Australia\", \"institution_id\": \"CSIRO\", \"mip_era\": \"CMIP6\", \"nominal_resolution\": \"250 km\", \"notes\": \"Exp: ESM-1pctCO2; Local ID: PI-1pct-01; Variable: tas ([\\'fld_s03i236\\'])\", \"parent_activity_id\": \"CMIP\", \"parent_experiment_id\": \"piControl\", \"parent_mip_era\": \"CMIP6\", \"parent_source_id\": \"ACCESS-ESM1-5\", \"parent_time_units\": \"days since 0101-01-01\", \"parent_variant_label\": \"r1i1p1f1\", \"product\": \"model-output\", \"realm\": \"atmos\", \"run_variant\": \"forcing: GHG, Oz, SA, Sl, Vl, BC, OC, (GHG = CO2, N2O, CH4, CFC11, CFC12, CFC113, HCFC22, HFC125, HFC134a)\", \"source\": \"ACCESS-ESM1.5 (2019): \\\\naerosol: CLASSIC (v1.0)\\\\natmos: HadGAM2 (r1.1, N96; 192 x 145 longitude/latitude; 38 levels; top level 39255 m)\\\\natmosChem: none\\\\nland: CABLE2.4\\\\nlandIce: none\\\\nocean: ACCESS-OM2 (MOM5, tripolar primarily 1deg; 360 x 300 longitude/latitude; 50 levels; top grid cell 0-10 m)\\\\nocnBgchem: WOMBAT (same grid as ocean)\\\\nseaIce: CICE4.1 (same grid as ocean)\", \"source_id\": \"ACCESS-ESM1-5\", \"source_type\": \"AOGCM\", \"sub_experiment\": \"none\", \"sub_experiment_id\": \"none\", \"table_id\": \"Amon\", \"table_info\": \"Creation Date:(30 April 2019) MD5:e14f55f257cceafb2523e41244962371\", \"title\": \"ACCESS-ESM1-5 output prepared for CMIP6\", \"variable_id\": \"tas\", \"variant_label\": \"r1i1p1f1\", \"version\": \"v20191115\", \"cmor_version\": \"3.4.0\", \"tracking_id\": \"hdl:21.14100/b3f4469e-2417-4123-bfb9-ef2cc8415cdd\", \"license\": \"CMIP6 model data produced by CSIRO is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License (https://creativecommons.org/licenses/).  Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment.  Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file).  The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.\"}',)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.bag as db\n",
    "items = db.read_text(files[0]) \n",
    "items.take(1) # Note: tuple containing a string, but I want a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Conventions': 'CF-1.7 CMIP-6.2',\n",
       "  'activity_id': 'CMIP',\n",
       "  'branch_method': 'standard',\n",
       "  'creation_date': '2019-11-15T02:38:12Z',\n",
       "  'data_specs_version': '01.00.30',\n",
       "  'experiment': '1 percent per year increase in CO2',\n",
       "  'experiment_id': '1pctCO2',\n",
       "  'external_variables': 'areacella',\n",
       "  'frequency': 'mon',\n",
       "  'further_info_url': 'https://furtherinfo.es-doc.org/CMIP6.CSIRO.ACCESS-ESM1-5.1pctCO2.none.r1i1p1f1',\n",
       "  'grid': 'native atmosphere N96 grid (145x192 latxlon)',\n",
       "  'grid_label': 'gn',\n",
       "  'history': '2019-11-15T02:38:12Z ; CMOR rewrote data to be consistent with CMIP6, CF-1.7 CMIP-6.2 and CF standards.',\n",
       "  'institution': 'Commonwealth Scientific and Industrial Research Organisation, Aspendale, Victoria 3195, Australia',\n",
       "  'institution_id': 'CSIRO',\n",
       "  'mip_era': 'CMIP6',\n",
       "  'nominal_resolution': '250 km',\n",
       "  'notes': \"Exp: ESM-1pctCO2; Local ID: PI-1pct-01; Variable: tas (['fld_s03i236'])\",\n",
       "  'parent_activity_id': 'CMIP',\n",
       "  'parent_experiment_id': 'piControl',\n",
       "  'parent_mip_era': 'CMIP6',\n",
       "  'parent_source_id': 'ACCESS-ESM1-5',\n",
       "  'parent_time_units': 'days since 0101-01-01',\n",
       "  'parent_variant_label': 'r1i1p1f1',\n",
       "  'product': 'model-output',\n",
       "  'realm': 'atmos',\n",
       "  'run_variant': 'forcing: GHG, Oz, SA, Sl, Vl, BC, OC, (GHG = CO2, N2O, CH4, CFC11, CFC12, CFC113, HCFC22, HFC125, HFC134a)',\n",
       "  'source': 'ACCESS-ESM1.5 (2019): \\naerosol: CLASSIC (v1.0)\\natmos: HadGAM2 (r1.1, N96; 192 x 145 longitude/latitude; 38 levels; top level 39255 m)\\natmosChem: none\\nland: CABLE2.4\\nlandIce: none\\nocean: ACCESS-OM2 (MOM5, tripolar primarily 1deg; 360 x 300 longitude/latitude; 50 levels; top grid cell 0-10 m)\\nocnBgchem: WOMBAT (same grid as ocean)\\nseaIce: CICE4.1 (same grid as ocean)',\n",
       "  'source_id': 'ACCESS-ESM1-5',\n",
       "  'source_type': 'AOGCM',\n",
       "  'sub_experiment': 'none',\n",
       "  'sub_experiment_id': 'none',\n",
       "  'table_id': 'Amon',\n",
       "  'table_info': 'Creation Date:(30 April 2019) MD5:e14f55f257cceafb2523e41244962371',\n",
       "  'title': 'ACCESS-ESM1-5 output prepared for CMIP6',\n",
       "  'variable_id': 'tas',\n",
       "  'variant_label': 'r1i1p1f1',\n",
       "  'version': 'v20191115',\n",
       "  'cmor_version': '3.4.0',\n",
       "  'tracking_id': 'hdl:21.14100/b3f4469e-2417-4123-bfb9-ef2cc8415cdd',\n",
       "  'license': 'CMIP6 model data produced by CSIRO is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License (https://creativecommons.org/licenses/).  Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment.  Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file).  The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.'},)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.bag as db\n",
    "items = db.read_text(files[0]).map(json.loads)\n",
    "items.take(1) # Note: tuple containing a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we parse our JSON data into proper Python objects (`dict`s, `list`s, etc.) we can perform more interesting queries by creating small Python functions to run on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.bag<loads, npartitions=185>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js = db.read_text('/g/data/dk92/notebooks/demo_data/cmip6_json/*.json').map(json.loads)\n",
    "js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Conventions': 'CF-1.7 CMIP-6.2',\n",
       "  'activity_id': 'CMIP',\n",
       "  'branch_method': 'standard',\n",
       "  'creation_date': '2019-11-15T02:37:21Z',\n",
       "  'data_specs_version': '01.00.30',\n",
       "  'experiment': '1 percent per year increase in CO2',\n",
       "  'experiment_id': '1pctCO2',\n",
       "  'external_variables': 'areacella',\n",
       "  'frequency': 'mon',\n",
       "  'further_info_url': 'https://furtherinfo.es-doc.org/CMIP6.CSIRO.ACCESS-ESM1-5.1pctCO2.none.r1i1p1f1',\n",
       "  'grid': 'native atmosphere N96 grid (145x192 latxlon)',\n",
       "  'grid_label': 'gn',\n",
       "  'history': '2019-11-15T02:37:21Z ; CMOR rewrote data to be consistent with CMIP6, CF-1.7 CMIP-6.2 and CF standards.',\n",
       "  'institution': 'Commonwealth Scientific and Industrial Research Organisation, Aspendale, Victoria 3195, Australia',\n",
       "  'institution_id': 'CSIRO',\n",
       "  'mip_era': 'CMIP6',\n",
       "  'nominal_resolution': '250 km',\n",
       "  'notes': \"Exp: ESM-1pctCO2; Local ID: PI-1pct-01; Variable: tasmax (['fld_s03i236_max'])\",\n",
       "  'parent_activity_id': 'CMIP',\n",
       "  'parent_experiment_id': 'piControl',\n",
       "  'parent_mip_era': 'CMIP6',\n",
       "  'parent_source_id': 'ACCESS-ESM1-5',\n",
       "  'parent_time_units': 'days since 0101-01-01',\n",
       "  'parent_variant_label': 'r1i1p1f1',\n",
       "  'product': 'model-output',\n",
       "  'realm': 'atmos',\n",
       "  'run_variant': 'forcing: GHG, Oz, SA, Sl, Vl, BC, OC, (GHG = CO2, N2O, CH4, CFC11, CFC12, CFC113, HCFC22, HFC125, HFC134a)',\n",
       "  'source': 'ACCESS-ESM1.5 (2019): \\naerosol: CLASSIC (v1.0)\\natmos: HadGAM2 (r1.1, N96; 192 x 145 longitude/latitude; 38 levels; top level 39255 m)\\natmosChem: none\\nland: CABLE2.4\\nlandIce: none\\nocean: ACCESS-OM2 (MOM5, tripolar primarily 1deg; 360 x 300 longitude/latitude; 50 levels; top grid cell 0-10 m)\\nocnBgchem: WOMBAT (same grid as ocean)\\nseaIce: CICE4.1 (same grid as ocean)',\n",
       "  'source_id': 'ACCESS-ESM1-5',\n",
       "  'source_type': 'AOGCM',\n",
       "  'sub_experiment': 'none',\n",
       "  'sub_experiment_id': 'none',\n",
       "  'table_id': 'Amon',\n",
       "  'table_info': 'Creation Date:(30 April 2019) MD5:e14f55f257cceafb2523e41244962371',\n",
       "  'title': 'ACCESS-ESM1-5 output prepared for CMIP6',\n",
       "  'variable_id': 'tasmax',\n",
       "  'variant_label': 'r1i1p1f1',\n",
       "  'version': 'v20191115',\n",
       "  'cmor_version': '3.4.0',\n",
       "  'tracking_id': 'hdl:21.14100/6c76911b-9543-47ee-9b8d-9e3e55a6de42',\n",
       "  'license': 'CMIP6 model data produced by CSIRO is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License (https://creativecommons.org/licenses/).  Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment.  Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file).  The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.'},\n",
       " {'Conventions': 'CF-1.7 CMIP-6.2',\n",
       "  'activity_id': 'CMIP',\n",
       "  'branch_method': 'standard',\n",
       "  'creation_date': '2019-11-15T02:38:12Z',\n",
       "  'data_specs_version': '01.00.30',\n",
       "  'experiment': '1 percent per year increase in CO2',\n",
       "  'experiment_id': '1pctCO2',\n",
       "  'external_variables': 'areacella',\n",
       "  'frequency': 'mon',\n",
       "  'further_info_url': 'https://furtherinfo.es-doc.org/CMIP6.CSIRO.ACCESS-ESM1-5.1pctCO2.none.r1i1p1f1',\n",
       "  'grid': 'native atmosphere N96 grid (145x192 latxlon)',\n",
       "  'grid_label': 'gn',\n",
       "  'history': '2019-11-15T02:38:12Z ; CMOR rewrote data to be consistent with CMIP6, CF-1.7 CMIP-6.2 and CF standards.',\n",
       "  'institution': 'Commonwealth Scientific and Industrial Research Organisation, Aspendale, Victoria 3195, Australia',\n",
       "  'institution_id': 'CSIRO',\n",
       "  'mip_era': 'CMIP6',\n",
       "  'nominal_resolution': '250 km',\n",
       "  'notes': \"Exp: ESM-1pctCO2; Local ID: PI-1pct-01; Variable: pr (['fld_s05i216'])\",\n",
       "  'parent_activity_id': 'CMIP',\n",
       "  'parent_experiment_id': 'piControl',\n",
       "  'parent_mip_era': 'CMIP6',\n",
       "  'parent_source_id': 'ACCESS-ESM1-5',\n",
       "  'parent_time_units': 'days since 0101-01-01',\n",
       "  'parent_variant_label': 'r1i1p1f1',\n",
       "  'product': 'model-output',\n",
       "  'realm': 'atmos',\n",
       "  'run_variant': 'forcing: GHG, Oz, SA, Sl, Vl, BC, OC, (GHG = CO2, N2O, CH4, CFC11, CFC12, CFC113, HCFC22, HFC125, HFC134a)',\n",
       "  'source': 'ACCESS-ESM1.5 (2019): \\naerosol: CLASSIC (v1.0)\\natmos: HadGAM2 (r1.1, N96; 192 x 145 longitude/latitude; 38 levels; top level 39255 m)\\natmosChem: none\\nland: CABLE2.4\\nlandIce: none\\nocean: ACCESS-OM2 (MOM5, tripolar primarily 1deg; 360 x 300 longitude/latitude; 50 levels; top grid cell 0-10 m)\\nocnBgchem: WOMBAT (same grid as ocean)\\nseaIce: CICE4.1 (same grid as ocean)',\n",
       "  'source_id': 'ACCESS-ESM1-5',\n",
       "  'source_type': 'AOGCM',\n",
       "  'sub_experiment': 'none',\n",
       "  'sub_experiment_id': 'none',\n",
       "  'table_id': 'Amon',\n",
       "  'table_info': 'Creation Date:(30 April 2019) MD5:e14f55f257cceafb2523e41244962371',\n",
       "  'title': 'ACCESS-ESM1-5 output prepared for CMIP6',\n",
       "  'variable_id': 'pr',\n",
       "  'variant_label': 'r1i1p1f1',\n",
       "  'version': 'v20191115',\n",
       "  'cmor_version': '3.4.0',\n",
       "  'tracking_id': 'hdl:21.14100/a8efb353-0fe8-4b24-bb8f-97bc10d69191',\n",
       "  'license': 'CMIP6 model data produced by CSIRO is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License (https://creativecommons.org/licenses/).  Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment.  Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file).  The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.'},\n",
       " {'Conventions': 'CF-1.7 CMIP-6.2',\n",
       "  'activity_id': 'CMIP',\n",
       "  'branch_method': 'standard',\n",
       "  'creation_date': '2019-11-21T05:16:17Z',\n",
       "  'data_specs_version': '01.00.30',\n",
       "  'experiment': '1 percent per year increase in CO2',\n",
       "  'experiment_id': '1pctCO2',\n",
       "  'external_variables': 'areacella',\n",
       "  'frequency': 'mon',\n",
       "  'further_info_url': 'https://furtherinfo.es-doc.org/CMIP6.CSIRO.ACCESS-ESM1-5.1pctCO2.none.r1i1p1f1',\n",
       "  'grid': 'native atmosphere N96 grid (145x192 latxlon)',\n",
       "  'grid_label': 'gn',\n",
       "  'history': '2019-11-21T05:16:17Z ; CMOR rewrote data to be consistent with CMIP6, CF-1.7 CMIP-6.2 and CF standards.',\n",
       "  'institution': 'Commonwealth Scientific and Industrial Research Organisation, Aspendale, Victoria 3195, Australia',\n",
       "  'institution_id': 'CSIRO',\n",
       "  'mip_era': 'CMIP6',\n",
       "  'nominal_resolution': '250 km',\n",
       "  'notes': \"Exp: ESM-1pctCO2; Local ID: PI-1pct-01; Variable: ua (['fld_s30i201'])\",\n",
       "  'parent_activity_id': 'CMIP',\n",
       "  'parent_experiment_id': 'piControl',\n",
       "  'parent_mip_era': 'CMIP6',\n",
       "  'parent_source_id': 'ACCESS-ESM1-5',\n",
       "  'parent_time_units': 'days since 0101-01-01',\n",
       "  'parent_variant_label': 'r1i1p1f1',\n",
       "  'product': 'model-output',\n",
       "  'realm': 'atmos',\n",
       "  'run_variant': 'forcing: GHG, Oz, SA, Sl, Vl, BC, OC, (GHG = CO2, N2O, CH4, CFC11, CFC12, CFC113, HCFC22, HFC125, HFC134a)',\n",
       "  'source': 'ACCESS-ESM1.5 (2019): \\naerosol: CLASSIC (v1.0)\\natmos: HadGAM2 (r1.1, N96; 192 x 145 longitude/latitude; 38 levels; top level 39255 m)\\natmosChem: none\\nland: CABLE2.4\\nlandIce: none\\nocean: ACCESS-OM2 (MOM5, tripolar primarily 1deg; 360 x 300 longitude/latitude; 50 levels; top grid cell 0-10 m)\\nocnBgchem: WOMBAT (same grid as ocean)\\nseaIce: CICE4.1 (same grid as ocean)',\n",
       "  'source_id': 'ACCESS-ESM1-5',\n",
       "  'source_type': 'AOGCM',\n",
       "  'sub_experiment': 'none',\n",
       "  'sub_experiment_id': 'none',\n",
       "  'table_id': 'Amon',\n",
       "  'table_info': 'Creation Date:(30 April 2019) MD5:e14f55f257cceafb2523e41244962371',\n",
       "  'title': 'ACCESS-ESM1-5 output prepared for CMIP6',\n",
       "  'variable_id': 'ua',\n",
       "  'variant_label': 'r1i1p1f1',\n",
       "  'version': 'v20191115',\n",
       "  'cmor_version': '3.4.0',\n",
       "  'tracking_id': 'hdl:21.14100/a749735e-4735-49c0-9ca3-85dd35a2e0b6',\n",
       "  'license': 'CMIP6 model data produced by CSIRO is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License (https://creativecommons.org/licenses/).  Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment.  Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file).  The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.'})"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repartition the bag so that `.take()` will return the number of elements as you want.\n",
    "js1 = js.repartition(1)\n",
    "js1.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the variables using `.map()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tasmax',\n",
       " 'pr',\n",
       " 'ua',\n",
       " 'ua',\n",
       " 'ua',\n",
       " 'huss',\n",
       " 'huss',\n",
       " 'cl',\n",
       " 'cl',\n",
       " 'cl',\n",
       " 'cl',\n",
       " 'cl',\n",
       " 'pfull',\n",
       " 'cl',\n",
       " 'cl',\n",
       " 'cl',\n",
       " 'cl',\n",
       " 'cl',\n",
       " 'cl',\n",
       " 'cl',\n",
       " 'cl',\n",
       " 'cl',\n",
       " 'cl',\n",
       " 'pfull',\n",
       " 'cl',\n",
       " 'rsus',\n",
       " 'rsus',\n",
       " 'rlus',\n",
       " 'rlus',\n",
       " 'vas',\n",
       " 'vas',\n",
       " 'sci',\n",
       " 'sci',\n",
       " 'prsn',\n",
       " 'rsutcs',\n",
       " 'prsn',\n",
       " 'tasmin',\n",
       " 'tasmin',\n",
       " 'tauv',\n",
       " 'tauv',\n",
       " 'evspsbl',\n",
       " 'evspsbl',\n",
       " 'hurs',\n",
       " 'hurs',\n",
       " 'rlutcs',\n",
       " 'rsutcs',\n",
       " 'rlutcs',\n",
       " 'prw',\n",
       " 'prw',\n",
       " 'prc',\n",
       " 'prc',\n",
       " 'ta',\n",
       " 'ta',\n",
       " 'ta',\n",
       " 'ta',\n",
       " 'rsut',\n",
       " 'zg',\n",
       " 'rsut',\n",
       " 'rlut',\n",
       " 'rlut',\n",
       " 'rsdscs',\n",
       " 'rsdscs',\n",
       " 'vas',\n",
       " 'ua',\n",
       " 'tasmax',\n",
       " 'ps',\n",
       " 'uas',\n",
       " 'zg',\n",
       " 'cl',\n",
       " 'evspsbl',\n",
       " 'wap',\n",
       " 'tas',\n",
       " 'hfls',\n",
       " 'hfss',\n",
       " 'zg',\n",
       " 'pr',\n",
       " 'cct',\n",
       " 'rsus',\n",
       " 'zg',\n",
       " 'rlut',\n",
       " 'rsut',\n",
       " 'psl',\n",
       " 'tauv',\n",
       " 'hurs',\n",
       " 'clt',\n",
       " 'tasmin',\n",
       " 'hus',\n",
       " 'sfcWind',\n",
       " 'rsdt',\n",
       " 'zg',\n",
       " 'va',\n",
       " 'rlds',\n",
       " 'rsds',\n",
       " 'huss',\n",
       " 'tauu',\n",
       " 'ts',\n",
       " 'cli',\n",
       " 'tasmax',\n",
       " 'cli',\n",
       " 'cli',\n",
       " 'cli',\n",
       " 'cli',\n",
       " 'cli',\n",
       " 'cli',\n",
       " 'cli',\n",
       " 'cli',\n",
       " 'cli',\n",
       " 'cli',\n",
       " 'rldscs',\n",
       " 'cli',\n",
       " 'cli',\n",
       " 'cli',\n",
       " 'cli',\n",
       " 'cli',\n",
       " 'hfls',\n",
       " 'hfls',\n",
       " 'clw',\n",
       " 'clw',\n",
       " 'clw',\n",
       " 'rldscs',\n",
       " 'clw',\n",
       " 'clw',\n",
       " 'clw',\n",
       " 'clw',\n",
       " 'clw',\n",
       " 'clw',\n",
       " 'clw',\n",
       " 'clw',\n",
       " 'clw',\n",
       " 'clw',\n",
       " 'hus',\n",
       " 'clw',\n",
       " 'clw',\n",
       " 'clw',\n",
       " 'hfss',\n",
       " 'hfss',\n",
       " 'va',\n",
       " 'va',\n",
       " 'va',\n",
       " 'va',\n",
       " 'sbl',\n",
       " 'hus',\n",
       " 'sbl',\n",
       " 'clt',\n",
       " 'clt',\n",
       " 'sfcWind',\n",
       " 'sfcWind',\n",
       " 'ts',\n",
       " 'ts',\n",
       " 'psl',\n",
       " 'psl',\n",
       " 'rtmt',\n",
       " 'hus',\n",
       " 'rtmt',\n",
       " 'rsdt',\n",
       " 'rsdt',\n",
       " 'uas',\n",
       " 'uas',\n",
       " 'clivi',\n",
       " 'clivi',\n",
       " 'phalf',\n",
       " 'phalf',\n",
       " 'hur',\n",
       " 'hus',\n",
       " 'hur',\n",
       " 'hur',\n",
       " 'hur',\n",
       " 'tauu',\n",
       " 'tauu',\n",
       " 'ps',\n",
       " 'ps',\n",
       " 'rsuscs',\n",
       " 'rsuscs',\n",
       " 'tas',\n",
       " 'pr',\n",
       " 'tas',\n",
       " 'wap',\n",
       " 'wap',\n",
       " 'wap',\n",
       " 'wap',\n",
       " 'rsds',\n",
       " 'rsds',\n",
       " 'rlds',\n",
       " 'rlds',\n",
       " 'ua']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js.map(lambda record: record['variable_id']).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out how many files with variable `cli` using `.filter()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_item = js.filter(lambda element: element['variable_id'] == 'cli')\n",
    "specific_item.count().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out how many data files have the nominal resolution of 250 km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_250km = js.filter(lambda element: element['nominal_resolution'] == '250 km').count().compute()\n",
    "d_250km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common to do many of these steps in one pipeline, only calling `compute` or `take` at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.bag<lambda, npartitions=1>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = (js1.filter(lambda element: element['variable_id'] == 'cli')\n",
    "           .map(lambda element: element['tracking_id']))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hdl:21.14100/bf8714fa-75e9-4991-8a78-65ff3c9d0c09',\n",
       " 'hdl:21.14100/07afabcd-2671-43b2-be80-8898b500c380',\n",
       " 'hdl:21.14100/bc0186a4-5032-4f5f-bb8f-f9ea1b1fb840',\n",
       " 'hdl:21.14100/03314b2e-bccd-43f2-9971-4ea064dd4168',\n",
       " 'hdl:21.14100/484c86d8-495d-4b19-aec9-9b64c9bb9c3e')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby and Foldby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we want to group data by some function or key.  We can do this either with the `.groupby` method, which is straightforward but forces a full shuffle of the data (expensive) or with the harder-to-use but faster `.foldby` method, which does a streaming combined groupby and reduction.\n",
    "\n",
    "*  `groupby`:  Shuffles data so that all items with the same key are in the same key-value pair\n",
    "*  `foldby`:  Walks through the data accumulating a result per key\n",
    "\n",
    "*Note: the full groupby is particularly bad. In actual workloads you would do well to use `foldby` or switch to `DataFrame`s if possible.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `groupby`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groupby collects items in your collection so that all items with the same value under some function are collected together into a key-value pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.bag<shuffle, npartitions=196>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = js.groupby(lambda item: item['institution_id'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CSIRO', 18), ('CSIRO', 19), ('CSIRO', 19), ('CSIRO', 19), ('CSIRO', 19), ('CSIRO', 20), ('CSIRO', 20), ('CSIRO', 20), ('IPSL', 3), ('IPSL', 4), ('IPSL', 4), ('IPSL', 4), ('IPSL', 4), ('IPSL', 4), ('IPSL', 8)]\n",
      "CPU times: user 2.05 s, sys: 76.2 ms, total: 2.12 s\n",
      "Wall time: 2.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = js.groupby(lambda item: item['institution_id']).starmap(lambda k, v: (k, len(v))).compute()\n",
    "print(sorted(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `foldby`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foldby can be quite odd at first.  It is similar to the following functions from other libraries:\n",
    "\n",
    "*  [`toolz.reduceby`](http://toolz.readthedocs.io/en/latest/streaming-analytics.html#streaming-split-apply-combine)\n",
    "*  [`pyspark.RDD.combineByKey`](http://abshinn.github.io/python/apache-spark/2014/10/11/using-combinebykey-in-apache-spark/)\n",
    "\n",
    "When using `foldby` you provide \n",
    "\n",
    "1.  A key function on which to group elements\n",
    "2.  A binary operator such as you would pass to `reduce` that you use to perform reduction per each group\n",
    "3.  A combine binary operator that can combine the results of two `reduce` calls on different parts of your dataset.\n",
    "\n",
    "Your reduction must be associative.  It will happen in parallel in each of the partitions of your dataset.  Then all of these intermediate results will be combined by the `combine` binary operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the number of institute with the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CSIRO', 154), ('IPSL', 31)]\n",
      "CPU times: user 514 ms, sys: 24 ms, total: 538 ms\n",
      "Wall time: 553 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This one is comparatively fast and produces the same result.\n",
    "from operator import add\n",
    "def incr(tot, _):\n",
    "    return tot+1\n",
    "\n",
    "result = js.foldby(key='institution_id', \n",
    "                   binop=incr, \n",
    "                   initial=0, \n",
    "                   combine=add, \n",
    "                   combine_initial=0).compute()\n",
    "print(sorted(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same reasons that Pandas is often faster than pure Python, `dask.dataframe` can be faster than `dask.bag`.  DataFrames are frequently the end-point of the \"messy\" part of data ingestionâ€”once the data can be made into a data-frame, then complex split-apply-combine logic will become much more straight-forward and efficient.\n",
    "\n",
    "You can transform a bag with a simple tuple or flat dictionary structure into a `dask.dataframe` with the `to_dataframe` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conventions</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>branch_method</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>data_specs_version</th>\n",
       "      <th>experiment</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>external_variables</th>\n",
       "      <th>frequency</th>\n",
       "      <th>further_info_url</th>\n",
       "      <th>grid</th>\n",
       "      <th>grid_label</th>\n",
       "      <th>history</th>\n",
       "      <th>institution</th>\n",
       "      <th>institution_id</th>\n",
       "      <th>mip_era</th>\n",
       "      <th>nominal_resolution</th>\n",
       "      <th>notes</th>\n",
       "      <th>parent_activity_id</th>\n",
       "      <th>parent_experiment_id</th>\n",
       "      <th>parent_mip_era</th>\n",
       "      <th>parent_source_id</th>\n",
       "      <th>parent_time_units</th>\n",
       "      <th>parent_variant_label</th>\n",
       "      <th>product</th>\n",
       "      <th>realm</th>\n",
       "      <th>run_variant</th>\n",
       "      <th>source</th>\n",
       "      <th>source_id</th>\n",
       "      <th>source_type</th>\n",
       "      <th>sub_experiment</th>\n",
       "      <th>sub_experiment_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>table_info</th>\n",
       "      <th>title</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>variant_label</th>\n",
       "      <th>version</th>\n",
       "      <th>cmor_version</th>\n",
       "      <th>tracking_id</th>\n",
       "      <th>license</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=185</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: to_dataframe, 555 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                Conventions activity_id branch_method creation_date data_specs_version experiment experiment_id external_variables frequency further_info_url    grid grid_label history institution institution_id mip_era nominal_resolution   notes parent_activity_id parent_experiment_id parent_mip_era parent_source_id parent_time_units parent_variant_label product   realm run_variant  source source_id source_type sub_experiment sub_experiment_id table_id table_info   title variable_id variant_label version cmor_version tracking_id license\n",
       "npartitions=185                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "                     object      object        object        object             object     object        object             object    object           object  object     object  object      object         object  object             object  object             object               object         object           object            object               object  object  object      object  object    object      object         object            object   object     object  object      object        object  object       object      object  object\n",
       "                        ...         ...           ...           ...                ...        ...           ...                ...       ...              ...     ...        ...     ...         ...            ...     ...                ...     ...                ...                  ...            ...              ...               ...                  ...     ...     ...         ...     ...       ...         ...            ...               ...      ...        ...     ...         ...           ...     ...          ...         ...     ...\n",
       "...                     ...         ...           ...           ...                ...        ...           ...                ...       ...              ...     ...        ...     ...         ...            ...     ...                ...     ...                ...                  ...            ...              ...               ...                  ...     ...     ...         ...     ...       ...         ...            ...               ...      ...        ...     ...         ...           ...     ...          ...         ...     ...\n",
       "                        ...         ...           ...           ...                ...        ...           ...                ...       ...              ...     ...        ...     ...         ...            ...     ...                ...     ...                ...                  ...            ...              ...               ...                  ...     ...     ...         ...     ...       ...         ...            ...               ...      ...        ...     ...         ...           ...     ...          ...         ...     ...\n",
       "                        ...         ...           ...           ...                ...        ...           ...                ...       ...              ...     ...        ...     ...         ...            ...     ...                ...     ...                ...                  ...            ...              ...               ...                  ...     ...     ...         ...     ...       ...         ...            ...               ...      ...        ...     ...         ...           ...     ...          ...         ...     ...\n",
       "Dask Name: to_dataframe, 555 tasks"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = js.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This now looks like a well-defined DataFrame, and we can apply Pandas-like computations to it efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a Dask DataFrame, how long does it take to do our prior computation of numbers of institues with the same name?  It turns out that `dask.dataframe.groupby()` is faster than `dask.bag.groupby()` ; but it still cannot match `dask.bag.foldby()` for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.dataframe.groupby.DataFrameGroupBy at 0x14b6fc3cbc10>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('institution_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 536 ms, sys: 38.8 ms, total: 575 ms\n",
      "Wall time: 1.24 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conventions</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>branch_method</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>data_specs_version</th>\n",
       "      <th>experiment</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>external_variables</th>\n",
       "      <th>frequency</th>\n",
       "      <th>further_info_url</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_experiment_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>table_info</th>\n",
       "      <th>title</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>variant_label</th>\n",
       "      <th>version</th>\n",
       "      <th>cmor_version</th>\n",
       "      <th>tracking_id</th>\n",
       "      <th>license</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>institution_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CSIRO</th>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IPSL</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Conventions  activity_id  branch_method  creation_date  \\\n",
       "institution_id                                                           \n",
       "CSIRO                   154          154            154            154   \n",
       "IPSL                     31           31             31             31   \n",
       "\n",
       "                data_specs_version  experiment  experiment_id  \\\n",
       "institution_id                                                  \n",
       "CSIRO                          154         154            154   \n",
       "IPSL                            31          31             31   \n",
       "\n",
       "                external_variables  frequency  further_info_url  ...  \\\n",
       "institution_id                                                   ...   \n",
       "CSIRO                          154        154               154  ...   \n",
       "IPSL                            31         31                31  ...   \n",
       "\n",
       "                sub_experiment_id  table_id  table_info  title  variable_id  \\\n",
       "institution_id                                                                \n",
       "CSIRO                         154       154         154    154          154   \n",
       "IPSL                           31        31           0     31           31   \n",
       "\n",
       "                variant_label  version  cmor_version  tracking_id  license  \n",
       "institution_id                                                              \n",
       "CSIRO                     154      154           154          154      154  \n",
       "IPSL                       31        0             0           31       31  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df.groupby('institution_id').count().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bags provide very general computation (any Python function.)  This generality\n",
    "comes at cost.  Bags have the following known limitations\n",
    "\n",
    "1.  Bag operations tend to be slower than array/dataframe computations in the\n",
    "    same way that Python tends to be slower than NumPy/Pandas\n",
    "2.  ``Bag.groupby`` is slow.  You should try to use ``Bag.foldby`` if possible.\n",
    "    Using ``Bag.foldby`` requires more thought. Even better, consider creating\n",
    "    a normalised dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
