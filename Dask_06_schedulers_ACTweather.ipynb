{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask Schedulers\n",
    "\n",
    "In this notebook we demonstrate how to set up different dask schedulers.\n",
    "* A few words about dask schedulers\n",
    "* Dask Schedulers on a single machine\n",
    "    * local threads\n",
    "    * local processes\n",
    "    * single thread\n",
    "* Apply scheduler options to weather station data\n",
    "* Distributed schedulers (local)\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Authors: NCI Virtual Research Environment Team\n",
    "- Keywords: Dask, Dataframe, schedulers\n",
    "- Creation Date: 2020-May\n",
    "- Lineage/Reference: This tutorial is referenced to [dask-tutorial](https://github.com/dask/dask-tutorial). It is important to note that ``dask`` is a rapidly evolving library and information contained in this tutorial may be obsolete at time of viewing.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedulers\n",
    "\n",
    "In the previous notebooks, we used `dask.delayed` and `dask.dataframe` to parallelise computations.\n",
    "This work built a *task graph* instead of executing immediately, with each *task* representing a function to call on some data. The full *graph* shows the relationship between all of the different tasks.\n",
    "\n",
    "When we wanted the actual result, we called `.compute()` or `.load()`, which handed the task graph off to a *scheduler*.\n",
    "\n",
    "**Schedulers are responsible for running a task graph and producing a result**.\n",
    "\n",
    "![](https://raw.githubusercontent.com/dask/dask-org/master/images/grid_search_schedule.gif)\n",
    "\n",
    "First, there are single machine schedulers that execute things in parallel using threads or processes (or synchronously for debugging). These are what we've used up until now. Second, there's the `dask.distributed` scheduler, which is newer and has more features than the single machine scheduler.\n",
    "\n",
    "In this notebook we'll first talk about the different schedulers. Then we'll use the `dask.distributed` scheduler in more depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Schedulers\n",
    "\n",
    "Dask separates computation description (task graphs) from execution (schedulers). This allows you to write code once, and run it locally or scale it out across a cluster.\n",
    "\n",
    "Dask has two families of task schedulers:\n",
    "\n",
    "- Single machine scheduler: This scheduler provides basic features on a local process or thread pool. This scheduler was made first and is the default. It is simple and cheap to use, although it can only be used on a single machine/node and does not scale.\n",
    "\n",
    "- Distributed scheduler: This scheduler is more sophisticated, offers more features, but also requires a bit more effort to set up. It can run locally or distributed across a cluster.\n",
    "\n",
    "For different computations you may find better performance with particular scheduler settings. This lesson helps you understand how to choose between and configure different schedulers, and provides guidelines on which one might be more appropriate.\n",
    "\n",
    "#### Local Threads\n",
    "\n",
    "```python\n",
    "- `dask.config.set(scheduler='threads')`  # overwrite default with threaded scheduler\n",
    "```\n",
    "\n",
    "The threaded scheduler executes computations with a local `multiprocessing.pool.ThreadPool`. It is lightweight and requires no setup. It introduces very little task overhead (around 50$\\mu$s per task) and, because everything occurs in the same process, it incurs no costs to transfer data between tasks. However, due to Pythonâ€™s Global Interpreter Lock (GIL), this scheduler only provides parallelism when your computation is dominated by non-Python code, as is primarily the case when operating on numeric data in NumPy arrays, Pandas DataFrames, or using any of the other C/C++/Cython based projects in the ecosystem.\n",
    "\n",
    "The threaded scheduler is the default choice for Dask Array, Dask DataFrame, and Dask Delayed. However, if your computation is dominated by processing pure Python objects like strings, dicts, or lists, then you may want to try one of the process-based schedulers below (we currently recommend the distributed scheduler on a local machine).\n",
    "\n",
    "#### Local Processes\n",
    "\n",
    "```python\n",
    "import dask.multiprocessing\n",
    "dask.config.set(scheduler='processes')  # overwrite default with multiprocessing scheduler\n",
    "```\n",
    "\n",
    "The multiprocessing scheduler executes computations with a local multiprocessing.Pool. It is lightweight to use and requires no setup. Every task and all of its dependencies are shipped to a local process, executed, and then their result is shipped back to the main process. This means that it is able to bypass issues with the GIL and provide parallelism even on computations that are dominated by pure Python code, such as those that process strings, dicts, and lists.\n",
    "\n",
    "However, moving data to remote processes and back can introduce performance penalties, particularly when the data being transferred between processes is large. The multiprocessing scheduler is an excellent choice when workflows are relatively linear, and so does not involve significant inter-task data transfer as well as when inputs and outputs are both small, like filenames and counts.\n",
    "\n",
    "#### Single Thread\n",
    "\n",
    "```python\n",
    "import dask\n",
    "dask.config.set(scheduler='synchronous')  # overwrite default with single-threaded scheduler\n",
    "```\n",
    "\n",
    "The single-threaded synchronous scheduler executes all computations in the local thread with no parallelism at all. This is particularly valuable for debugging and profiling, which are more difficult when using threads or processes.\n",
    "\n",
    "For example, when using iPython or Jupyter notebooks, the `%debug`, `%pdb`, or `%prun` magics will not work well when using the parallel Dask schedulers (they were not designed to be used in a parallel computing context). However, if you run into an exception and want to step into the debugger, you may wish to rerun your computation under the single-threaded scheduler where these tools will function properly.\n",
    "\n",
    "Here we discuss the *local* schedulers - schedulers that run only on a single machine. We experimented with these in the Dask_02 lesson. In each case we change the scheduler used in a few different ways:\n",
    "\n",
    "- By providing a `scheduler=` keyword argument to `compute`:\n",
    "\n",
    "```python\n",
    "max_rain.compute(scheduler='processes')\n",
    "# or \n",
    "max_rain.compute(scheduler='synchronous')\n",
    "```\n",
    "\n",
    "- Using `dask.set_options`:\n",
    "\n",
    "```python\n",
    "# Use multiprocessing in this block\n",
    "with dask.set_options(scheduler='processes'):\n",
    "    max_rain.compute()\n",
    "# Use multiprocessing globally\n",
    "dask.set_options(scheduler='synchronous')\n",
    "```\n",
    "\n",
    "Here we repeat a simple dataframe computation from the previous section using the different schedulers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide path to the ACT rainfall data used in Dask_05\n",
    "filename = os.path.join('/g/data/dk92/notebooks/demo_data/', 'Weather_Stations_ACT','IDCJAC0009_*_*','IDCJAC0009*.csv')\n",
    "df = dd.read_csv(filename)\n",
    "# rename column headers\n",
    "df.columns = ['code','station','year','month','day','rainfall','period','quality']\n",
    "# Maximum rainfall\n",
    "max_rain=df.rainfall.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dd.Scalar<series-..., dtype=float64>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.79 s, sys: 1.34 s, total: 4.13 s\n",
      "Wall time: 2.82 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = max_rain.compute()  # this uses threads by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 473 ms, sys: 102 ms, total: 575 ms\n",
      "Wall time: 3.07 s\n"
     ]
    }
   ],
   "source": [
    "import dask.multiprocessing\n",
    "%time _ = max_rain.compute(scheduler='processes')  # this uses processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.03 s, sys: 606 ms, total: 2.63 s\n",
      "Wall time: 2.84 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = max_rain.compute(scheduler='synchronous')  # This uses a single thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the threaded and multiprocessing schedulers use the same number of workers as cores. You can change this using the `num_workers` keyword in the same way that you specified `scheduler` above:\n",
    "\n",
    "```\n",
    "max_rain.compute(scheduler='processes', num_workers=2)\n",
    "```\n",
    "\n",
    "To see how many cores you have on your computer, you can use `multiprocessing.cpu_count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import cpu_count\n",
    "cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Questions to Consider:\n",
    "\n",
    "- How much speedup is possible for this task (hint, look at the graph)?\n",
    "- Given how many cores are on this machine, how much faster could the parallel schedulers be than the single-threaded scheduler?\n",
    "- How much faster was using threads over a single thread? Why does this differ from the optimal speedup?\n",
    "- Why is the multiprocessing scheduler so much slower here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In what cases would you want to use one scheduler over another?\n",
    "\n",
    "http://dask.pydata.org/en/latest/setup/single-machine.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Scheduler\n",
    "\n",
    "The `dask.distributed` system is composed of a single centralized scheduler and many worker processes. [Deploying](http://dask.pydata.org/en/latest/setup.html) a remote Dask cluster involves some additional effort. But doing things locally just involves creating a `Client` object, which lets you interact with the \"cluster\" (local threads or processes on your machine). For more information see [here](http://dask.pydata.org/en/latest/setup/single-distributed.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "# Setup a local cluster.\n",
    "# By default this sets up 1 worker per core\n",
    "client = Client()\n",
    "client.cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, creating a `Client` makes it the default scheduler. Any calls to `.compute` will use the cluster your `client` is attached to (See http://dask.pydata.org/en/latest/scheduling.html for how to specify which scheduler to use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 615 ms, sys: 69.5 ms, total: 685 ms\n",
      "Wall time: 2.49 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "322.1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time max_rain.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Questions to Consider\n",
    "\n",
    "- How does this compare to the optimal parallel speedup?\n",
    "- Why is this faster than the threaded scheduler?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Run the following computations while looking at the diagnostics page (dask dashboard). In each case what is taking the most time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dask\n",
    "import pandas as pd\n",
    "filename = os.path.join('/g/data/dk92/notebooks/demo_data/', 'Weather_Stations_ACT','IDCJAC0009_*_*','IDCJAC0009*.csv')\n",
    "import dask.dataframe as dd\n",
    "ddf = dd.read_csv(filename)\n",
    "ddf.columns = ['code','station','year','month','day','rainfall','period','quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1754661"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 1.) How many rows are in our dataset?\n",
    "len(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "period    418018\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 2.) In total, how many days records were taken?\n",
    "period = pd.read_parquet('/g/data/dk92/notebooks/demo_data/ACT_weather.parquet', columns=['period'], engine='pyarrow')\n",
    "period.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station\n",
       "42010       41\n",
       "70000    10222\n",
       "70011    11574\n",
       "70014     8377\n",
       "70015     6168\n",
       "         ...  \n",
       "70354     1010\n",
       "71073     4099\n",
       "72011     2606\n",
       "72157      377\n",
       "73148      243\n",
       "Name: period, Length: 125, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 3.) In total, how many non-record days from each weather station?\n",
    "ddf.groupby(\"station\").period.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station\n",
       "42010    1.372022\n",
       "70000    1.767808\n",
       "70011    1.760142\n",
       "70014    1.689061\n",
       "70015    1.791328\n",
       "           ...   \n",
       "70354    1.790016\n",
       "71073    2.526155\n",
       "72011    2.510485\n",
       "72157    2.541190\n",
       "73148    1.709147\n",
       "Name: rainfall, Length: 125, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 4.) What was the average rainfall from each station?\n",
    "ddf.groupby(\"station\").rainfall.mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the client\n",
    "\n",
    "Before moving on to the next exercise, make sure to close your client or stop this kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More...\n",
    "\n",
    "The distributed scheduler is more sophisticated than the single machine schedulers. It can compute asynchronously, and also provides an API similar to that of `concurrent.futures`. For further information you can see the docs http://distributed.readthedocs.io/en/latest/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "https://docs.dask.org/en/latest/scheduling.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
